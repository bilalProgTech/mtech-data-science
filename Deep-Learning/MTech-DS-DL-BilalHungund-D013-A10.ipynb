{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MTech-DS-DL-BilalHungund-D013-A10.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bilalProgTech/mtech-data-science/blob/master/Deep-Learning/MTech-DS-DL-BilalHungund-D013-A10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xGt6ZAaOIYuD"
      },
      "source": [
        "import os\n",
        "import datetime\n",
        "\n",
        "import IPython\n",
        "import IPython.display\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "\n",
        "mpl.rcParams['figure.figsize'] = (8, 6)\n",
        "mpl.rcParams['axes.grid'] = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9V4bXIlfImyE"
      },
      "source": [
        "zip_path = tf.keras.utils.get_file(\n",
        "    origin='https://storage.googleapis.com/tensorflow/tf-keras-datasets/jena_climate_2009_2016.csv.zip',\n",
        "    fname='jena_climate_2009_2016.csv.zip',\n",
        "    extract=True)\n",
        "csv_path, _ = os.path.splitext(zip_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MVNA11_VImu3"
      },
      "source": [
        "data = pd.read_csv(csv_path)\n",
        "# slice [start:stop:step], starting from index 5 take every 6th record.\n",
        "data = data[5::6]\n",
        "\n",
        "date_time = pd.to_datetime(data.pop('Date Time'), format='%d.%m.%Y %H:%M:%S')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_oPmdYbImse"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z03d_whZImoK"
      },
      "source": [
        "wv = data['wv (m/s)']\n",
        "bad_wv = wv == -9999.0\n",
        "wv[bad_wv] = 0.0\n",
        "\n",
        "max_wv = data['max. wv (m/s)']\n",
        "bad_max_wv = max_wv == -9999.0\n",
        "max_wv[bad_max_wv] = 0.0\n",
        "\n",
        "# The above inplace edits are reflected in the DataFrame\n",
        "data['wv (m/s)'].min()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cDvHHxbJImi8"
      },
      "source": [
        "plt.hist2d(data['wd (deg)'], data['wv (m/s)'], bins=(50, 50), vmax=400)\n",
        "plt.colorbar()\n",
        "plt.xlabel('Wind Direction [deg]')\n",
        "plt.ylabel('Wind Velocity [m/s]')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBqlIzE8Imf6"
      },
      "source": [
        "wv = data.pop('wv (m/s)')\n",
        "max_wv = data.pop('max. wv (m/s)')\n",
        "\n",
        "# Convert to radians.\n",
        "wd_rad = data.pop('wd (deg)')*np.pi / 180\n",
        "\n",
        "# Calculate the wind x and y components.\n",
        "data['Wx'] = wv*np.cos(wd_rad)\n",
        "data['Wy'] = wv*np.sin(wd_rad)\n",
        "\n",
        "# Calculate the max wind x and y components.\n",
        "data['max Wx'] = max_wv*np.cos(wd_rad)\n",
        "data['max Wy'] = max_wv*np.sin(wd_rad)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XOxkrrlwImdw"
      },
      "source": [
        "plt.hist2d(data['Wx'], data['Wy'], bins=(50, 50), vmax=400)\n",
        "plt.colorbar()\n",
        "plt.xlabel('Wind X [m/s]')\n",
        "plt.ylabel('Wind Y [m/s]')\n",
        "ax = plt.gca()\n",
        "ax.axis('tight')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-zARpNcKImZg"
      },
      "source": [
        "timestamp_s = date_time.map(datetime.datetime.timestamp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8KbhfA9ImVc"
      },
      "source": [
        "day = 24*60*60\n",
        "year = (365.2425)*day\n",
        "\n",
        "data['Day sin'] = np.sin(timestamp_s * (2 * np.pi / day))\n",
        "data['Day cos'] = np.cos(timestamp_s * (2 * np.pi / day))\n",
        "data['Year sin'] = np.sin(timestamp_s * (2 * np.pi / year))\n",
        "data['Year cos'] = np.cos(timestamp_s * (2 * np.pi / year))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GjxvFCBQImSH"
      },
      "source": [
        "plt.plot(np.array(data['Day sin'])[:25])\n",
        "plt.plot(np.array(data['Day cos'])[:25])\n",
        "plt.xlabel('Time [h]')\n",
        "plt.title('Time of day signal')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-cd5HLo9ImO1"
      },
      "source": [
        "fft = tf.signal.rfft(data['T (degC)'])\n",
        "f_per_dataset = np.arange(0, len(fft))\n",
        "\n",
        "n_samples_h = len(data['T (degC)'])\n",
        "hours_per_year = 24*365.2524\n",
        "years_per_dataset = n_samples_h/(hours_per_year)\n",
        "\n",
        "f_per_year = f_per_dataset/years_per_dataset\n",
        "plt.step(f_per_year, np.abs(fft))\n",
        "plt.xscale('log')\n",
        "plt.ylim(0, 400000)\n",
        "plt.xlim([0.1, max(plt.xlim())])\n",
        "plt.xticks([1, 365.2524], labels=['1/Year', '1/day'])\n",
        "_ = plt.xlabel('Frequency (log scale)')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UweSfvViImLb"
      },
      "source": [
        "column_indices = {name: i for i, name in enumerate(data.columns)}\n",
        "\n",
        "n = len(data)\n",
        "train_df = data[0:int(n*0.7)]\n",
        "val_df = data[int(n*0.7):int(n*0.9)]\n",
        "test_df = data[int(n*0.9):]\n",
        "\n",
        "num_features = data.shape[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qdpXOsX-J2La"
      },
      "source": [
        "Normalizing the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HED7J6oQImHn"
      },
      "source": [
        "train_mean = train_df.mean()\n",
        "train_std = train_df.std()\n",
        "\n",
        "train_df = (train_df - train_mean) / train_std\n",
        "val_df = (val_df - train_mean) / train_std\n",
        "test_df = (test_df - train_mean) / train_std"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lKyI3QVlImEG"
      },
      "source": [
        "df_std = (data - train_mean) / train_std\n",
        "df_std = df_std.melt(var_name='Column', value_name='Normalized')\n",
        "plt.figure(figsize=(12, 6))\n",
        "ax = sns.violinplot(x='Column', y='Normalized', data=df_std)\n",
        "_ = ax.set_xticklabels(data.keys(), rotation=90)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EdKD5XcNImA1"
      },
      "source": [
        "class WindowGenerator():\n",
        "  def __init__(self, input_width, label_width, shift,\n",
        "               train_df=train_df, val_df=val_df, test_df=test_df,\n",
        "               label_columns=None):\n",
        "    # Store the raw data.\n",
        "    self.train_df = train_df\n",
        "    self.val_df = val_df\n",
        "    self.test_df = test_df\n",
        "\n",
        "    # Work out the label column indices.\n",
        "    self.label_columns = label_columns\n",
        "    if label_columns is not None:\n",
        "      self.label_columns_indices = {name: i for i, name in\n",
        "                                    enumerate(label_columns)}\n",
        "    self.column_indices = {name: i for i, name in\n",
        "                           enumerate(train_df.columns)}\n",
        "\n",
        "    # Work out the window parameters.\n",
        "    self.input_width = input_width\n",
        "    self.label_width = label_width\n",
        "    self.shift = shift\n",
        "\n",
        "    self.total_window_size = input_width + shift\n",
        "\n",
        "    self.input_slice = slice(0, input_width)\n",
        "    self.input_indices = np.arange(self.total_window_size)[self.input_slice]\n",
        "\n",
        "    self.label_start = self.total_window_size - self.label_width\n",
        "    self.labels_slice = slice(self.label_start, None)\n",
        "    self.label_indices = np.arange(self.total_window_size)[self.labels_slice]\n",
        "\n",
        "  def __repr__(self):\n",
        "    return '\\n'.join([\n",
        "        f'Total window size: {self.total_window_size}',\n",
        "        f'Input indices: {self.input_indices}',\n",
        "        f'Label indices: {self.label_indices}',\n",
        "        f'Label column name(s): {self.label_columns}'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O6ijWmG0Il0u"
      },
      "source": [
        "def split_window(self, features):\n",
        "  inputs = features[:, self.input_slice, :]\n",
        "  labels = features[:, self.labels_slice, :]\n",
        "  if self.label_columns is not None:\n",
        "    labels = tf.stack(\n",
        "        [labels[:, :, self.column_indices[name]] for name in self.label_columns],\n",
        "        axis=-1)\n",
        "\n",
        "  # Slicing doesn't preserve static shape information, so set the shapes\n",
        "  # manually. This way the `tf.data.Datasets` are easier to inspect.\n",
        "  inputs.set_shape([None, self.input_width, None])\n",
        "  labels.set_shape([None, self.label_width, None])\n",
        "\n",
        "  return inputs, labels\n",
        "\n",
        "WindowGenerator.split_window = split_window"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iN_ndBdcKLhy"
      },
      "source": [
        "def plot(self, model=None, plot_col='T (degC)', max_subplots=3):\n",
        "  inputs, labels = self.example\n",
        "  plt.figure(figsize=(12, 8))\n",
        "  plot_col_index = self.column_indices[plot_col]\n",
        "  max_n = min(max_subplots, len(inputs))\n",
        "  for n in range(max_n):\n",
        "    plt.subplot(3, 1, n+1)\n",
        "    plt.ylabel(f'{plot_col} [normed]')\n",
        "    plt.plot(self.input_indices, inputs[n, :, plot_col_index],\n",
        "             label='Inputs', marker='.', zorder=-10)\n",
        "\n",
        "    if self.label_columns:\n",
        "      label_col_index = self.label_columns_indices.get(plot_col, None)\n",
        "    else:\n",
        "      label_col_index = plot_col_index\n",
        "\n",
        "    if label_col_index is None:\n",
        "      continue\n",
        "\n",
        "    plt.scatter(self.label_indices, labels[n, :, label_col_index],\n",
        "                edgecolors='k', label='Labels', c='#2ca02c', s=64)\n",
        "    if model is not None:\n",
        "      predictions = model(inputs)\n",
        "      plt.scatter(self.label_indices, predictions[n, :, label_col_index],\n",
        "                  marker='X', edgecolors='k', label='Predictions',\n",
        "                  c='#ff7f0e', s=64)\n",
        "\n",
        "    if n == 0:\n",
        "      plt.legend()\n",
        "\n",
        "  plt.xlabel('Time [h]')\n",
        "\n",
        "WindowGenerator.plot = plot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G3EK6QvHKLY4"
      },
      "source": [
        "def make_dataset(self, data):\n",
        "  data = np.array(data, dtype=np.float32)\n",
        "  ds = tf.keras.preprocessing.timeseries_dataset_from_array(\n",
        "      data=data,\n",
        "      targets=None,\n",
        "      sequence_length=self.total_window_size,\n",
        "      sequence_stride=1,\n",
        "      shuffle=True,\n",
        "      batch_size=32,)\n",
        "\n",
        "  ds = ds.map(self.split_window)\n",
        "\n",
        "  return ds\n",
        "\n",
        "WindowGenerator.make_dataset = make_dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vSIjZj4GKLTg"
      },
      "source": [
        "@property\n",
        "def train(self):\n",
        "  return self.make_dataset(self.train_df)\n",
        "\n",
        "@property\n",
        "def val(self):\n",
        "  return self.make_dataset(self.val_df)\n",
        "\n",
        "@property\n",
        "def test(self):\n",
        "  return self.make_dataset(self.test_df)\n",
        "\n",
        "@property\n",
        "def example(self):\n",
        "  \"\"\"Get and cache an example batch of `inputs, labels` for plotting.\"\"\"\n",
        "  result = getattr(self, '_example', None)\n",
        "  if result is None:\n",
        "    # No example batch was found, so get one from the `.train` dataset\n",
        "    result = next(iter(self.train))\n",
        "    # And cache it for next time\n",
        "    self._example = result\n",
        "  return result\n",
        "\n",
        "WindowGenerator.train = train\n",
        "WindowGenerator.val = val\n",
        "WindowGenerator.test = test\n",
        "WindowGenerator.example = example"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X7J-Hcz6KLN9"
      },
      "source": [
        "MAX_EPOCHS = 20\n",
        "\n",
        "def compile_and_fit(model, window, patience=2):\n",
        "  early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
        "                                                    patience=patience,\n",
        "                                                    mode='min')\n",
        "\n",
        "  model.compile(loss=tf.losses.MeanSquaredError(),\n",
        "                optimizer=tf.optimizers.Adam(),\n",
        "                metrics=[tf.metrics.MeanAbsoluteError()])\n",
        "\n",
        "  history = model.fit(window.train, epochs=MAX_EPOCHS,\n",
        "                      validation_data=window.val,\n",
        "                      callbacks=[early_stopping])\n",
        "  return history"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VNDKq3EyKLIm"
      },
      "source": [
        "OUT_STEPS = 24\n",
        "multi_window = WindowGenerator(input_width=24,\n",
        "                               label_width=OUT_STEPS,\n",
        "                               shift=OUT_STEPS)\n",
        "\n",
        "multi_window.plot()\n",
        "multi_window"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qz2ZWlR7KLFL"
      },
      "source": [
        "ms_lstm = tf.keras.Sequential([\n",
        "                               tf.keras.layers.LSTM(32, return_sequences=False),\n",
        "                               tf.keras.layers.Dense(OUT_STEPS*num_features),\n",
        "                               tf.keras.layers.Reshape([OUT_STEPS, num_features])\n",
        "])\n",
        "\n",
        "history_lstm = compile_and_fit(ms_lstm, multi_window )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DXuwVPsJKLAh"
      },
      "source": [
        "ms_rnn  = tf.keras.Sequential([\n",
        "                               tf.keras.layers.SimpleRNN(32, return_sequences=False),\n",
        "                               tf.keras.layers.Dense(OUT_STEPS*num_features),\n",
        "                               tf.keras.layers.Reshape([OUT_STEPS, num_features])\n",
        "])\n",
        "\n",
        "history_rnn = compile_and_fit(ms_rnn, multi_window )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UjvSIcQ3KteL"
      },
      "source": [
        "ms_gru  = tf.keras.Sequential([\n",
        "                               tf.keras.layers.GRU(32, return_sequences=False),\n",
        "                               tf.keras.layers.Dense(OUT_STEPS*num_features),\n",
        "                               tf.keras.layers.Reshape([OUT_STEPS, num_features])\n",
        "])\n",
        "\n",
        "history_gru = compile_and_fit(ms_gru, multi_window )"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}