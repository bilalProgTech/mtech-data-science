{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MTech-DS-DL-BilalHungund-D013-A5.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMsgKhhX3D4bjAFpRI5rRSN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bilalProgTech/mtech-data-science/blob/master/Deep-Learning/MTech-DS-DL-BilalHungund-D013-A5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYeU3rYHJf8P"
      },
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import numpy as np\n",
        "import requests\n",
        "import cv2\n",
        "import PIL.Image\n",
        "import urllib\n",
        "\n",
        "class1 = requests.get(\"http://www.image-net.org/api/text/imagenet.synset.geturls?wnid=n04037443\")\n",
        "print(class1.content)\n",
        "class1_soup = BeautifulSoup(class1.content, 'html.parser')\n",
        "class2 = requests.get(\"http://www.image-net.org/api/text/imagenet.synset.geturls?wnid=n02814533\")\n",
        "print(class2.content)\n",
        "class2_soup = BeautifulSoup(class2.content, 'html.parser')\n",
        "\n",
        "class3 = requests.get(\"http://www.image-net.org/api/text/imagenet.synset.geturls?wnid=n02918964\")\n",
        "print(class3.content)\n",
        "class3_soup = BeautifulSoup(class3.content, 'html.parser')\n",
        "\n",
        "\n",
        "\n",
        "class1_str_soup=str(class1_soup)\n",
        "type(class1_str_soup)\n",
        "class1_split_urls=class1_str_soup.split('\\r\\n')\n",
        "print(len(class1_split_urls))\n",
        "\n",
        "\n",
        "class2_str_soup=str(class2_soup)\n",
        "type(class2_str_soup)\n",
        "class2_split_urls=class2_str_soup.split('\\r\\n')\n",
        "print(len(class2_split_urls))\n",
        "\n",
        "\n",
        "class3_str_soup=str(class3_soup)\n",
        "type(class3_str_soup)\n",
        "class3_split_urls=class3_str_soup.split('\\r\\n')\n",
        "print(len(class3_split_urls))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "luMwJAZAJuVb"
      },
      "source": [
        "!mkdir /content/train \n",
        "!mkdir /content/train/class1\n",
        "!mkdir /content/train/class2 \n",
        "!mkdir /content/train/class3 \n",
        "\n",
        "!mkdir /content/validation\n",
        "!mkdir /content/validation/class1\n",
        "!mkdir /content/validation/class2\n",
        "!mkdir /content/validation/class3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aY2PB5raJuWN"
      },
      "source": [
        "img_rows, img_cols = 32, 32 \n",
        "input_shape = (img_rows, img_cols, 3)\n",
        "def url_to_image(url):\n",
        "\tresp = urllib.request.urlopen(url)\n",
        "\timage = np.asarray(bytearray(resp.read()), dtype=\"uint8\")\n",
        "\timage = cv2.imdecode(image, cv2.IMREAD_COLOR)\n",
        " \n",
        "\treturn image\n",
        "\n",
        "n_of_training_images=100\n",
        "for progress in range(n_of_training_images):\n",
        "    if(progress%20==0):\n",
        "        print(progress)\n",
        "    if not class1_split_urls[progress] == None:\n",
        "      try:\n",
        "        I = url_to_image(class1_split_urls[progress])\n",
        "        if (len(I.shape))==3: \n",
        "          save_path = '/content/train/class1/img'+str(progress)+'.jpg'\n",
        "          cv2.imwrite(save_path,I)\n",
        "\n",
        "      except:\n",
        "        None\n",
        "\n",
        "for progress in range(n_of_training_images):\n",
        "    if(progress%20==0):\n",
        "        print(progress)\n",
        "    if not class2_split_urls[progress] == None:\n",
        "      try:\n",
        "        I = url_to_image(class2_split_urls[progress])\n",
        "        if (len(I.shape))==3: \n",
        "          save_path = '/content/train/class2/img'+str(progress)+'.jpg'\n",
        "          cv2.imwrite(save_path,I)\n",
        "\n",
        "      except:\n",
        "        None\n",
        "\n",
        "for progress in range(n_of_training_images):\n",
        "    if(progress%20==0):\n",
        "        print(progress)\n",
        "    if not class3_split_urls[progress] == None:\n",
        "      try:\n",
        "        I = url_to_image(class3_split_urls[progress])\n",
        "        if (len(I.shape))==3: \n",
        "          save_path = '/content/train/class3/img'+str(progress)+'.jpg'\n",
        "          cv2.imwrite(save_path,I)\n",
        "\n",
        "      except:\n",
        "        None\n",
        "\n",
        "\n",
        "for progress in range(50):\n",
        "    if(progress%20==0):\n",
        "        print(progress)\n",
        "    if not class1_split_urls[progress] == None:\n",
        "      try:\n",
        "        I = url_to_image(class1_split_urls[n_of_training_images+progress])\n",
        "        if (len(I.shape))==3: \n",
        "          save_path = '/content/validation/class1/img'+str(progress)+'.jpg'\n",
        "          cv2.imwrite(save_path,I)\n",
        "\n",
        "      except:\n",
        "        None\n",
        "\n",
        "for progress in range(50):\n",
        "    if(progress%20==0):\n",
        "        print(progress)\n",
        "    if not class2_split_urls[progress] == None:\n",
        "      try:\n",
        "        I = url_to_image(class2_split_urls[n_of_training_images+progress])\n",
        "        if (len(I.shape))==3: \n",
        "          save_path = '/content/validation/class2/img'+str(progress)+'.jpg'\n",
        "          cv2.imwrite(save_path,I)\n",
        "\n",
        "      except:\n",
        "        None\n",
        "\n",
        "for progress in range(50):\n",
        "    if(progress%20==0):\n",
        "        print(progress)\n",
        "    if not class3_split_urls[progress] == None:\n",
        "      try:\n",
        "        I = url_to_image(class3_split_urls[n_of_training_images+progress])\n",
        "        if (len(I.shape))==3: \n",
        "          save_path = '/content/validation/class3/img'+str(progress)+'.jpg'\n",
        "          cv2.imwrite(save_path,I)\n",
        "\n",
        "      except:\n",
        "        None\n",
        "\n",
        "\n",
        "print(\"\\nTRAIN:\\n\")          \n",
        "print(\"\\nlist the files inside class1 directory:\\n\")        \n",
        "!ls /content/train/class1 \n",
        "print(\"\\nlist the files inside class2 directory:\\n\")\n",
        "!ls /content/train/class2 \n",
        "print(\"\\nlist the files inside class3 directory:\\n\")\n",
        "!ls /content/train/class3 \n",
        "\n",
        "print(\"\\nVALIDATION:\\n\")\n",
        "print(\"\\nlist the files inside class1 directory:\\n\")        \n",
        "!ls /content/validation/class1 \n",
        "print(\"\\nlist the files inside class2 directory:\\n\")\n",
        "!ls /content/validation/class2 \n",
        "print(\"\\nlist the files inside class3 directory:\\n\")\n",
        "!ls /content/validation/class3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O1ke2TD0J9Qg"
      },
      "source": [
        "# Q2)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oh1_-UCWJujm"
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
        "\n",
        "train_datagen  = ImageDataGenerator(rescale=1./255,\n",
        "                                 horizontal_flip=True,\n",
        "                                 validation_split=0.2)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "    \n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        '/content/train/',\n",
        "        target_size=(img_rows, img_cols),\n",
        "        batch_size=32,\n",
        "        class_mode='categorical',\n",
        "        subset='training')\n",
        "\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "        '/content/train/',\n",
        "        target_size=(img_rows, img_cols),\n",
        "        batch_size=32,\n",
        "        class_mode='categorical',\n",
        "        subset='validation'\n",
        "        )\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "        '/content/validation/',\n",
        "        target_size=(img_rows, img_cols),\n",
        "        batch_size=32,\n",
        "        class_mode='categorical'\n",
        "        )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W33VaR_lJuwk"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "model=tf.keras.models.Sequential()\n",
        "model.add(tf.keras.layers.Conv2D(512,(32,32),padding='valid',activation='relu',input_shape=(32,32,3)))\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "model.add(tf.keras.layers.Dense(512,activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(256,activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(128,activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(3,activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PR6piKlOJu8d"
      },
      "source": [
        "history=model.fit_generator(\n",
        "        train_generator,\n",
        "        epochs=100,\n",
        "        validation_data=validation_generator,\n",
        "        verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fh1FnfnnJvHt"
      },
      "source": [
        "model.evaluate_generator(generator=test_generator)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}