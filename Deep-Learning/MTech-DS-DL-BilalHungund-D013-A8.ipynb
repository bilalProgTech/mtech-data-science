{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MTech-DS-DL-BilalHungund-D013-A8.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bilalProgTech/mtech-data-science/blob/master/Deep-Learning/MTech-DS-DL-BilalHungund-D013-A8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KdJbCOYqeM4x"
      },
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import numpy as np\n",
        "import requests\n",
        "import cv2\n",
        "import PIL.Image\n",
        "import urllib\n",
        "\n",
        "class1 = requests.get(\"http://www.image-net.org/api/text/imagenet.synset.geturls?wnid=n04037443\")#indian\n",
        "print(class1.content)\n",
        "class1_soup = BeautifulSoup(class1.content, 'html.parser')\n",
        "class2 = requests.get(\"http://www.image-net.org/api/text/imagenet.synset.geturls?wnid=n02504458\")#african\n",
        "print(class2.content)\n",
        "class2_soup = BeautifulSoup(class2.content, 'html.parser')\n",
        "\n",
        "class3 = requests.get(\"http://www.image-net.org/api/text/imagenet.synset.geturls?wnid=n01871265\")#tusker\n",
        "print(class3.content)\n",
        "class3_soup = BeautifulSoup(class3.content, 'html.parser')\n",
        "\n",
        "\n",
        "\n",
        "class1_str_soup=str(class1_soup)\n",
        "type(class1_str_soup)\n",
        "class1_split_urls=class1_str_soup.split('\\r\\n')\n",
        "print(len(class1_split_urls))\n",
        "\n",
        "\n",
        "class2_str_soup=str(class2_soup)\n",
        "type(class2_str_soup)\n",
        "class2_split_urls=class2_str_soup.split('\\r\\n')\n",
        "print(len(class2_split_urls))\n",
        "\n",
        "\n",
        "class3_str_soup=str(class3_soup)\n",
        "type(class3_str_soup)\n",
        "class3_split_urls=class3_str_soup.split('\\r\\n')\n",
        "print(len(class3_split_urls))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AWEM3mDvg_yg"
      },
      "source": [
        "!mkdir /content/train \n",
        "!mkdir /content/train/class1\n",
        "!mkdir /content/train/class2 \n",
        "!mkdir /content/train/class3 \n",
        "\n",
        "!mkdir /content/validation\n",
        "!mkdir /content/validation/class1\n",
        "!mkdir /content/validation/class2\n",
        "!mkdir /content/validation/class3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ldtJ17JhHiE"
      },
      "source": [
        "img_rows, img_cols = 32, 32 \n",
        "input_shape = (img_rows, img_cols, 3)\n",
        "def url_to_image(url):\n",
        "\tresp = urllib.request.urlopen(url)\n",
        "\timage = np.asarray(bytearray(resp.read()), dtype=\"uint8\")\n",
        "\timage = cv2.imdecode(image, cv2.IMREAD_COLOR)\n",
        " \n",
        "\treturn image\n",
        "\n",
        "n_of_training_images=150\n",
        "for progress in range(n_of_training_images):\n",
        "    if(progress%20==0):\n",
        "        print(progress)\n",
        "    if not class1_split_urls[progress] == None:\n",
        "      try:\n",
        "        I = url_to_image(class1_split_urls[progress])\n",
        "        if (len(I.shape))==3: \n",
        "          save_path = '/content/train/class1/img'+str(progress)+'.jpg'\n",
        "          cv2.imwrite(save_path,I)\n",
        "\n",
        "      except:\n",
        "        None\n",
        "\n",
        "for progress in range(n_of_training_images):\n",
        "    if(progress%20==0):\n",
        "        print(progress)\n",
        "    if not class2_split_urls[progress] == None:\n",
        "      try:\n",
        "        I = url_to_image(class2_split_urls[progress])\n",
        "        if (len(I.shape))==3: \n",
        "          save_path = '/content/train/class2/img'+str(progress)+'.jpg'\n",
        "          cv2.imwrite(save_path,I)\n",
        "\n",
        "      except:\n",
        "        None\n",
        "\n",
        "for progress in range(n_of_training_images):\n",
        "    if(progress%20==0):\n",
        "        print(progress)\n",
        "    if not class3_split_urls[progress] == None:\n",
        "      try:\n",
        "        I = url_to_image(class3_split_urls[progress])\n",
        "        if (len(I.shape))==3: \n",
        "          save_path = '/content/train/class3/img'+str(progress)+'.jpg'\n",
        "          cv2.imwrite(save_path,I)\n",
        "\n",
        "      except:\n",
        "        None\n",
        "\n",
        "\n",
        "for progress in range(50):\n",
        "    if(progress%20==0):\n",
        "        print(progress)\n",
        "    if not class1_split_urls[progress] == None:\n",
        "      try:\n",
        "        I = url_to_image(class1_split_urls[n_of_training_images+progress])\n",
        "        if (len(I.shape))==3: \n",
        "          save_path = '/content/validation/class1/img'+str(progress)+'.jpg'\n",
        "          cv2.imwrite(save_path,I)\n",
        "\n",
        "      except:\n",
        "        None\n",
        "\n",
        "for progress in range(50):\n",
        "    if(progress%20==0):\n",
        "        print(progress)\n",
        "    if not class2_split_urls[progress] == None:\n",
        "      try:\n",
        "        I = url_to_image(class2_split_urls[n_of_training_images+progress])\n",
        "        if (len(I.shape))==3: \n",
        "          save_path = '/content/validation/class2/img'+str(progress)+'.jpg'\n",
        "          cv2.imwrite(save_path,I)\n",
        "\n",
        "      except:\n",
        "        None\n",
        "\n",
        "for progress in range(50):\n",
        "    if(progress%20==0):\n",
        "        print(progress)\n",
        "    if not class3_split_urls[progress] == None:\n",
        "      try:\n",
        "        I = url_to_image(class3_split_urls[n_of_training_images+progress])\n",
        "        if (len(I.shape))==3: \n",
        "          save_path = '/content/validation/class3/img'+str(progress)+'.jpg'\n",
        "          cv2.imwrite(save_path,I)\n",
        "\n",
        "      except:\n",
        "        None\n",
        "\n",
        "\n",
        "print(\"\\nTRAIN:\\n\")          \n",
        "print(\"\\nlist the files inside class1 directory:\\n\")        \n",
        "!ls /content/train/class1 \n",
        "print(\"\\nlist the files inside class2 directory:\\n\")\n",
        "!ls /content/train/class2 \n",
        "print(\"\\nlist the files inside class3 directory:\\n\")\n",
        "!ls /content/train/class3 \n",
        "\n",
        "print(\"\\nVALIDATION:\\n\")\n",
        "print(\"\\nlist the files inside class1 directory:\\n\")        \n",
        "!ls /content/validation/class1 \n",
        "print(\"\\nlist the files inside class2 directory:\\n\")\n",
        "!ls /content/validation/class2 \n",
        "print(\"\\nlist the files inside class3 directory:\\n\")\n",
        "!ls /content/validation/class3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-W_ffMOdhNQj"
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
        "\n",
        "train_datagen  = ImageDataGenerator(rescale=1./255,\n",
        "                                 horizontal_flip=True,\n",
        "                                 validation_split=0.2)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "    \n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        '/content/train/',\n",
        "        target_size=(img_rows, img_cols),\n",
        "        batch_size=32,\n",
        "        class_mode='categorical',\n",
        "        subset='training')\n",
        "\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "        '/content/train/',\n",
        "        target_size=(img_rows, img_cols),\n",
        "        batch_size=32,\n",
        "        class_mode='categorical',\n",
        "        subset='validation'\n",
        "        )\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "        '/content/validation/',\n",
        "        target_size=(img_rows, img_cols),\n",
        "        batch_size=32,\n",
        "        class_mode='categorical'\n",
        "        )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ejdC0p_jh3Xl"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.applications import ResNet50,ResNet152V2,VGG16\n",
        "from keras.preprocessing import image\n",
        "from keras.applications.resnet50 import preprocess_input, decode_predictions\n",
        "from tensorflow.python.keras.models import Sequential\n",
        "from tensorflow.python.keras.layers import Dense\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\"\"\"\n",
        "model=tf.keras.applications.ResNet152V2(\n",
        "    include_top=True,\n",
        "    weights=\"imagenet\",\n",
        "    input_tensor=None,\n",
        "    input_shape=None,\n",
        "    pooling=None,\n",
        "    classes=1000,\n",
        "    classifier_activation=\"softmax\",\n",
        ")\n",
        "\"\"\"\n",
        "model_resnet50=Sequential()\n",
        "model_resnet50.add(ResNet50(include_top = False, pooling = 'avg', weights = \"imagenet\"))\n",
        "model_resnet50.add(Dense(3, activation = 'softmax'))\n",
        "model_resnet50.layers[0].trainable = False\n",
        "\n",
        "model_resnet152=Sequential()\n",
        "model_resnet152.add(ResNet152V2(include_top = False, pooling = 'avg', weights = \"imagenet\"))\n",
        "model_resnet152.add(Dense(3, activation = 'softmax'))\n",
        "model_resnet152.layers[0].trainable = False\n",
        "\n",
        "model_vgg16=Sequential()\n",
        "model_vgg16.add(VGG16(include_top = False, pooling = 'avg', weights = \"imagenet\"))\n",
        "model_vgg16.add(Dense(3, activation = 'softmax'))\n",
        "model_vgg16.layers[0].trainable = False\n",
        "\n",
        "#model_vgg16=tf.keras.applications.VGG16(weights='imagenet')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uEnDTb7ri1Nl"
      },
      "source": [
        "model_resnet50.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "model_resnet50.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DkFnARX9vfax"
      },
      "source": [
        "model_resnet152.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "model_resnet152.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u1qKXDQivfIH"
      },
      "source": [
        "model_vgg16.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "model_vgg16.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_vBnKTH8rukL"
      },
      "source": [
        "from tensorflow.python.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "cb_early_stopper = EarlyStopping(monitor = 'val_loss', patience = 3)\n",
        "cb_checkpointer = ModelCheckpoint(filepath = 'best.hdf5', monitor = 'val_loss', save_best_only = True, mode = 'auto')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-OUjpoXinJ4"
      },
      "source": [
        "model_resnet50_history=model_resnet50.fit_generator(train_generator,epochs=10,validation_data=validation_generator,callbacks=[cb_checkpointer, cb_early_stopper])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zRy10ncRivDU"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.figure(1, figsize = (15,8)) \n",
        "    \n",
        "plt.subplot(221)  \n",
        "plt.plot(model_resnet50_history.history['accuracy'])  \n",
        "plt.plot(model_resnet50_history.history['val_accuracy'])  \n",
        "plt.title('model accuracy')  \n",
        "plt.ylabel('accuracy')  \n",
        "plt.xlabel('epoch')  \n",
        "plt.legend(['train', 'valid']) \n",
        "    \n",
        "plt.subplot(222)  \n",
        "plt.plot(model_resnet50_history.history['loss'])  \n",
        "plt.plot(model_resnet50_history.history['val_loss'])  \n",
        "plt.title('model loss')  \n",
        "plt.ylabel('loss')  \n",
        "plt.xlabel('epoch')  \n",
        "plt.legend(['train', 'valid']) \n",
        "\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lCHwmgFHwYbF"
      },
      "source": [
        "model_resnet152_history=model_resnet152.fit_generator(train_generator,epochs=50,validation_data=validation_generator,callbacks=[cb_checkpointer, cb_early_stopper])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gPXD2PxEwoHj"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.figure(1, figsize = (15,8)) \n",
        "    \n",
        "plt.subplot(221)  \n",
        "plt.plot(model_resnet152_history.history['accuracy'])  \n",
        "plt.plot(model_resnet152_history.history['val_accuracy'])  \n",
        "plt.title('model accuracy')  \n",
        "plt.ylabel('accuracy')  \n",
        "plt.xlabel('epoch')  \n",
        "plt.legend(['train', 'valid']) \n",
        "    \n",
        "plt.subplot(222)  \n",
        "plt.plot(model_resnet152_history.history['loss'])  \n",
        "plt.plot(model_resnet152_history.history['val_loss'])  \n",
        "plt.title('model loss')  \n",
        "plt.ylabel('loss')  \n",
        "plt.xlabel('epoch')  \n",
        "plt.legend(['train', 'valid']) \n",
        "\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LMxmSe1Iwyyy"
      },
      "source": [
        "model_vgg16_history=model_vgg16.fit_generator(train_generator,epochs=50,validation_data=validation_generator,callbacks=[cb_checkpointer, cb_early_stopper])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xw_sfmehxCkw"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.figure(1, figsize = (15,8)) \n",
        "    \n",
        "plt.subplot(221)  \n",
        "plt.plot(model_vgg16_history.history['accuracy'])  \n",
        "plt.plot(model_vgg16_history.history['val_accuracy'])  \n",
        "plt.title('model accuracy')  \n",
        "plt.ylabel('accuracy')  \n",
        "plt.xlabel('epoch')  \n",
        "plt.legend(['train', 'valid']) \n",
        "    \n",
        "plt.subplot(222)  \n",
        "plt.plot(model_vgg16_history.history['loss'])  \n",
        "plt.plot(model_vgg16_history.history['val_loss'])  \n",
        "plt.title('model loss')  \n",
        "plt.ylabel('loss')  \n",
        "plt.xlabel('epoch')  \n",
        "plt.legend(['train', 'valid']) \n",
        "\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}